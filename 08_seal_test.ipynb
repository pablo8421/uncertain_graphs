{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nasty-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "from igraph import Graph\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import community as community_louvain\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handed-postcard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>asim_likelihood</th>\n",
       "      <th>edge_exists_original</th>\n",
       "      <th>edge_exists_modified</th>\n",
       "      <th>seal_likelihood</th>\n",
       "      <th>dataset</th>\n",
       "      <th>modification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>dancer_01</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>dancer_01</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>dancer_01</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>dancer_01</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.504137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>dancer_01</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from    to  asim_likelihood  edge_exists_original  edge_exists_modified  \\\n",
       "0     0     1         0.036421                   0.0                   0.0   \n",
       "1     0    10         0.563449                   1.0                   0.0   \n",
       "2     0   100         0.002656                   0.0                   0.0   \n",
       "3     0  1000         0.000246                   0.0                   0.0   \n",
       "4     0  1001         0.504137                   0.0                   0.0   \n",
       "\n",
       "   seal_likelihood    dataset modification  \n",
       "0           0.0238  dancer_01         base  \n",
       "1           0.5691  dancer_01         base  \n",
       "2           0.0716  dancer_01         base  \n",
       "3           0.0236  dancer_01         base  \n",
       "4           0.0614  dancer_01         base  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\n",
    "    'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Repository/Experiments/datasets/dancer_01/results/random_01.txt')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unnecessary-laptop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asim_likelihood: 0.8429287\n",
      " train_f1_score: 0.2742304309586631\n",
      " test_f1_score: 0.2681144288995615\n",
      " exists_f1_score: 0.27037773359840955\n",
      " exists_all_f1_score: 0.27584575348947243\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, E_train, E_test, Y_train,Y_test = train_test_split(dataset['asim_likelihood'], dataset['edge_exists_original'], dataset['edge_exists_modified'],\n",
    "                                         test_size=0.3, random_state=4269, stratify=dataset['edge_exists_modified'])\n",
    "\n",
    "# 'Train', get best threshold, via f1_score\n",
    "precision, recall, thresholds = precision_recall_curve(Y_train, X_train)\n",
    "f1_scores = np.divide(2*recall*precision, (recall+precision), out=np.zeros_like(recall+precision), where=(recall+precision!=0))\n",
    "\n",
    "# Get the threshold with the best results\n",
    "threshold = thresholds[np.argmax(f1_scores)]\n",
    "train_f1_score = np.max(f1_scores)\n",
    "# Get test best score\n",
    "test_f1_score = f1_score((X_test > threshold).astype('float64').values, Y_test)\n",
    "# Comparing to the original graph (just the test ones)\n",
    "exists_test_f1_score = f1_score((X_test > threshold).astype('float64').values, E_test)\n",
    "# Comparing to the original graph (ALL OF THEM!)\n",
    "exists_all_f1_score = f1_score(np.concatenate(((X_train > threshold).astype('float64').values, (X_test > threshold).astype('float64').values)), np.concatenate((E_train,E_test)))\n",
    "\n",
    "print('asim_likelihood: '+str(threshold)+'\\n', 'train_f1_score: '+str(train_f1_score)+'\\n', 'test_f1_score: '+str(test_f1_score)+'\\n', 'exists_f1_score: '+str(exists_test_f1_score)+'\\n', 'exists_all_f1_score: '+str(exists_all_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "structured-integration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seal_likelihood: 0.9324\n",
      " train_f1_score: 0.22650150931612367\n",
      " test_f1_score: 0.20456802383316783\n",
      " exists_f1_score: 0.21222768798313424\n",
      " exists_all_f1_score: 0.2290681502086231\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, E_train, E_test, Y_train,Y_test = train_test_split(dataset['seal_likelihood'], dataset['edge_exists_original'], dataset['edge_exists_modified'],\n",
    "                                         test_size=0.3, random_state=4269, stratify=dataset['edge_exists_modified'])\n",
    "\n",
    "# 'Train', get best threshold, via f1_score\n",
    "precision, recall, thresholds = precision_recall_curve(Y_train, X_train)\n",
    "f1_scores = np.divide(2*recall*precision, (recall+precision), out=np.zeros_like(recall+precision), where=(recall+precision!=0))\n",
    "\n",
    "# Get the threshold with the best results\n",
    "threshold = thresholds[np.argmax(f1_scores)]\n",
    "train_f1_score = np.max(f1_scores)\n",
    "# Get test best score\n",
    "test_f1_score = f1_score((X_test > threshold).astype('float64').values, Y_test)\n",
    "# Comparing to the original graph (just the test ones)\n",
    "exists_test_f1_score = f1_score((X_test > threshold).astype('float64').values, E_test)\n",
    "# Comparing to the original graph (ALL OF THEM!)\n",
    "exists_all_f1_score = f1_score(np.concatenate(((X_train > threshold).astype('float64').values, (X_test > threshold).astype('float64').values)), np.concatenate((E_train,E_test)))\n",
    "\n",
    "print('seal_likelihood: '+str(threshold)+'\\n', 'train_f1_score: '+str(train_f1_score)+'\\n', 'test_f1_score: '+str(test_f1_score)+'\\n', 'exists_f1_score: '+str(exists_test_f1_score)+'\\n', 'exists_all_f1_score: '+str(exists_all_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suburban-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_edges = dataset[(dataset['edge_exists_modified']==1) | ((dataset['asim_likelihood']>threshold))].copy()\n",
    "selected_edges[['from','to']].to_csv('random_01_seal_graph.txt', sep=' ', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "careful-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'dancer_01'\n",
    "community_file = 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Experiments/datasets/dancer_01/dancer_01_comm.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pleased-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load community belonging\n",
    "communities = {}\n",
    "with open(community_file) as f:\n",
    "    for line in f:\n",
    "       (key, val) = line.split()\n",
    "       communities[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "average-hotel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>file_name</th>\n",
       "      <th>method</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Louvain-igraph</td>\n",
       "      <td>P</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Louvain-igraph</td>\n",
       "      <td>P*/P</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Louvain-igraph</td>\n",
       "      <td>Modularity</td>\n",
       "      <td>0.638858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Louvain-igraph</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.684448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Fastgreedy</td>\n",
       "      <td>P</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset                 file_name          method      metric     value\n",
       "0  dancer_01  random_01_seal_graph.txt  Louvain-igraph           P  8.000000\n",
       "1  dancer_01  random_01_seal_graph.txt  Louvain-igraph        P*/P  0.750000\n",
       "2  dancer_01  random_01_seal_graph.txt  Louvain-igraph  Modularity  0.638858\n",
       "3  dancer_01  random_01_seal_graph.txt  Louvain-igraph         NMI  0.684448\n",
       "4  dancer_01  random_01_seal_graph.txt      Fastgreedy           P  7.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unweighted analysis\n",
    "\n",
    "results_rows = []\n",
    "\n",
    "# Value to be used during all of the runs\n",
    "p_size = len(set(communities.values()))\n",
    "\n",
    "# Iterate generated graphs\n",
    "for file_name in ['random_01_seal_graph.txt']:\n",
    "    # Load graph\n",
    "    graph = Graph.Read_Ncol(file_name, directed=False)\n",
    "    \n",
    "    # Add community belonging\n",
    "    for vertex in graph.vs:\n",
    "        vertex['community'] = communities[vertex['name']]\n",
    "\n",
    "    # louvian\n",
    "    method = 'Louvain-igraph'\n",
    "\n",
    "    louvian = ig.Graph.community_multilevel(graph, return_levels=True)\n",
    "    louvian = louvian[len(louvian)-1]\n",
    "    p_louvian = len(set(louvian.membership))\n",
    "\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P',\n",
    "                 'value':p_louvian})    \n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P*/P',\n",
    "                 'value':p_size/p_louvian})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'Modularity',\n",
    "                 'value':graph.modularity(louvian.membership)})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'NMI',\n",
    "                 'value':normalized_mutual_info_score(graph.vs['community'], louvian.membership)})\n",
    "\n",
    "    # FastGreedy\n",
    "    method = 'Fastgreedy'\n",
    "\n",
    "    fg = ig.Graph.community_fastgreedy(graph)\n",
    "    p_fg = fg.optimal_count\n",
    "    fg = fg.as_clustering()\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P',\n",
    "                 'value':p_fg})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P*/P',\n",
    "                 'value':p_size/p_fg})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'Modularity',\n",
    "                 'value':graph.modularity(fg.membership)})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'NMI',\n",
    "                 'value':normalized_mutual_info_score(graph.vs['community'], fg.membership)})\n",
    "    # Infomap\n",
    "    method = 'Infomap'\n",
    "\n",
    "    infomap = ig.Graph.community_infomap(graph)\n",
    "    p_im = len(set(infomap.membership))\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P',\n",
    "                 'value':p_im})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P*/P',\n",
    "                 'value':p_size/p_im})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'Modularity',\n",
    "                 'value':graph.modularity(infomap.membership)})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'NMI',\n",
    "                 'value':normalized_mutual_info_score(graph.vs['community'], infomap.membership)})\n",
    "\n",
    "    # Label Propagation\n",
    "    method = 'Label Propagation'\n",
    "\n",
    "    lp = ig.Graph.community_label_propagation(graph)\n",
    "    p_lp = len(set(lp.membership))\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P',\n",
    "                 'value':p_lp})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P*/P',\n",
    "                 'value':p_size/p_lp})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'Modularity',\n",
    "                 'value':graph.modularity(lp.membership)})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'NMI',\n",
    "                 'value':normalized_mutual_info_score(graph.vs['community'], lp.membership)})\n",
    "\n",
    "    # Louvain\n",
    "    method = 'Louvain'\n",
    "\n",
    "    # Creating nx Graph to for other Louvain implementation\n",
    "    nxG = nx.Graph()\n",
    "    nxG.add_nodes_from([vertex.index for vertex in graph.vs])\n",
    "    nxG.add_edges_from([edge.tuple for edge in graph.es])\n",
    "\n",
    "    lv_partition = community_louvain.best_partition(nxG)\n",
    "    p_lv = len(set(lv_partition.values()))\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P',\n",
    "                 'value':p_lv})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'P*/P',\n",
    "                 'value':p_size/p_lv})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'Modularity',\n",
    "                 'value':graph.modularity(lv_partition.values())})\n",
    "    results_rows.append({'dataset':dataset_name, 'file_name':file_name, 'method':method, 'metric':'NMI',\n",
    "                 'value':normalized_mutual_info_score(graph.vs['community'], pd.Series(lv_partition.values()))})\n",
    "\n",
    "community_algos = pd.DataFrame(results_rows)\n",
    "\n",
    "community_algos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "junior-carrier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>file_name</th>\n",
       "      <th>method</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Louvain-igraph</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.684448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Fastgreedy</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.656665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Infomap</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.547304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Label Propagation</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.687467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dancer_01</td>\n",
       "      <td>random_01_seal_graph.txt</td>\n",
       "      <td>Louvain</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.687754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset                 file_name             method metric     value\n",
       "3   dancer_01  random_01_seal_graph.txt     Louvain-igraph    NMI  0.684448\n",
       "7   dancer_01  random_01_seal_graph.txt         Fastgreedy    NMI  0.656665\n",
       "11  dancer_01  random_01_seal_graph.txt            Infomap    NMI  0.547304\n",
       "15  dancer_01  random_01_seal_graph.txt  Label Propagation    NMI  0.687467\n",
       "19  dancer_01  random_01_seal_graph.txt            Louvain    NMI  0.687754"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_algos[community_algos['metric']=='NMI']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
