instrumentalness = mean(instrumentalness, na.rm=TRUE),
liveness = mean(liveness, na.rm=TRUE),
valence = mean(valence, na.rm=TRUE)
)
#Add min
radar_data <- rbind(c(0,0,0,0,0,-60,0,0,0,0,0,0), radar_data)
#Add max
radar_data <- rbind(c(1200000,100,1,1,12,0,1,1,1,1,1,1), radar_data)
#Radar chart
radarchart( radar_data  , axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,20,5), cglwd=0.8,
#custom labels
vlcex=0.8
)
#Correlation
ggcorr(tracks, method = c("everything", "pearson"), label = TRUE)
columns <- list('danceability','energy','speechiness','acousticness','instrumentalness','liveness','valence')
View(genre_weights)
View(genre_weights)
View(genre_connections)
View(genre_connections)
#not really a good idea
#Creating the graph object
net <- graph_from_data_frame(d=genre_connections, vertices=genre_weights, directed=F)
# Community detection based on edge betweenness (Newman-Girvan)
ceb <- cluster_edge_betweenness(net, weights = E(graph)$weight)
# Community detection based on edge betweenness (Newman-Girvan)
ceb <- cluster_edge_betweenness(net, weights = E(net)$weight)
# Amount of communities
length(ceb)
Community = induced_subgraph(net, ceb[[i]])
###########  Answer #########
for(i in seq_along(ceb)) {
Community = induced_subgraph(net, ceb[[i]])
V(Community)$name <- ceb[[i]]        ## To preserve original node numbers
EL = as_edgelist(Community)
VL = V(Community)$name
FileName = paste0("D:/Pablo/clases/UJM/2. Semester, 2021/Data Mining/Project/communities/community_", i, ".dat")
write.table(VL, FileName, row.names=FALSE, col.names=FALSE, sep=",")
}
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
group_by(artist,genres) %>% #Reduce to one row per artist, to change how weight behave
separate_rows(genres, sep = ",") %>% #Separate each genre into a row
select(id, name, genres) %>% #Select only the rows we need
rename(genre = genres)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
group_by(artist,genres) %>% #Reduce to one row per artist, to change how weight behave
separate_rows(genres, sep = ",") %>% #Separate each genre into a row
select(id, name, genres) %>% #Select only the rows we need
rename(genre = genres)
View(genre_tracks)
View(genre_tracks)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
group_by(artist,genres) %>% #Reduce to one row per artist, to change how weight behave
separate_rows(genres, sep = ",") %>% #Separate each genre into a row
select(artist, genres) %>% #Select only the rows we need
rename(genre = genres)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
group_by(artist,genres) %>% #Reduce to one row per artist, to change how weight behave
separate_rows(genres, sep = ",") %>% #Separate each genre into a row
select(artist, genres) %>% #Select only the rows we need
rename(genre = genres)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
group_by(artist,genres) %>% #Reduce to one row per artist, to change how weight behave
#separate_rows(genres, sep = ",") %>% #Separate each genre into a row
#select(artist, genres) %>% #Select only the rows we need
rename(genre = genres)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
group_by(artist,genres) %>% #Reduce to one row per artist, to change how weight behave
#separate_rows(genres, sep = ",") %>% #Separate each genre into a row
select(artist, genres) %>% #Select only the rows we need
rename(genre = genres)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
select(artist, genres) %>% #Select only the rows we need
unique() %>% # Remove weight by amount of songs by each artist
#separate_rows(genres, sep = ",") %>% #Separate each genre into a row
rename(genre = genres)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
select(artist, genres) %>% #Select only the rows we need
unique() %>% # Remove weight by amount of songs by each artist
separate_rows(genres, sep = ",") %>% #Separate each genre into a row
rename(genre = genres)
#Group by genre, count songs with specific genre
genre_weights <- genre_tracks %>%
group_by(genre) %>%
count() %>%
rename(weight = n)
#The connections in the graph
genre_connections <-
#inner_join(genre_tracks, genre_tracks, by=c("id" = "id"), suffix = c(".x", ".y")) %>% #Inner joinning with the same song
inner_join(genre_tracks, genre_tracks, by=c("artist" = "artist"), suffix = c(".x", ".y")) %>% #Inner joinning with the same artist
filter(genre.x != genre.y) %>% # Remove connections with itself
select(genre.x, genre.y) %>% # Select only the pair of genres
filter(genre.x < genre.y) %>% # To avoid duplicates, keep only ordered genres
group_by(genre.x, genre.y) %>% # Group by genre pairs
count() %>%
rename(weight = n)
#not really a good idea
#Creating the graph object
net <- graph_from_data_frame(d=genre_connections, vertices=genre_weights, directed=F)
# Community detection based on edge betweenness (Newman-Girvan)
ceb <- cluster_edge_betweenness(net, weights = E(net)$weight)
# Amount of communities
length(ceb)
###########  Answer #########
for(i in seq_along(ceb)) {
Community = induced_subgraph(net, ceb[[i]])
V(Community)$name <- ceb[[i]]        ## To preserve original node numbers
EL = as_edgelist(Community)
VL = V(Community)$name
FileName = paste0("D:/Pablo/clases/UJM/2. Semester, 2021/Data Mining/Project/communities/community_", i, ".dat")
write.table(VL, FileName, row.names=FALSE, col.names=FALSE, sep=",")
}
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
select(artist, genres) %>% #Select only the rows we need
group_by(artist, genres) %>% #Grouping to keep uniques
count() %>% #Count
unique() %>% # Remove weight by amount of songs by each artist
separate_rows(genres, sep = ",") %>% #Separate each genre into a row
rename(genre = genres)
View(genre_tracks)
View(genre_tracks)
#Get track/genre tuple
genre_tracks <- tracks %>%
filter(name!='') %>%  #Filter unknown songs
filter(genres!='') %>% #Filter songs without genres
select(artist, genres) %>% #Select only the rows we need
group_by(artist, genres) %>% #Grouping to keep uniques
count() %>% #Count
#unique() %>% # Remove weight by amount of songs by each artist
separate_rows(genres, sep = ",") %>% #Separate each genre into a row
rename(genre = genres)
rm(list = ls())
# base path
datsets_location <- 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Graphs Visualization/datasets/'
# Loading data
wikipedia_nodes <- read.csv(file=paste(datsets_location,'wikipedia/Wiki-Vote.txt',sep = ''), sep = '\t')
net <- graph_from_data_frame(d=wikipedia_nodes, directed=FALSE)
# Loading used libraries
library(tidyverse)
library(igraph)
library(GGally)
library(stats)
#Creating the graph object
net <- graph_from_data_frame(d=wikipedia_nodes, directed=FALSE)
# Calculationg
num_vertex <- length(V(net))
num_edges <- length(E(net))
#https://igraph.org/r/doc/diameter.html
net_density <- graph.density(net)
#Degree distribution
vertex_degrees <- as.data.frame(table(degree(net))) %>% rename(degree = Var1)
#https://igraph.org/r/doc/diameter.html
net_diameter <- diameter(net)
#TODO Ask does it really requires memberships?
# if not, how to work without memebership
#https://igraph.org/r/doc/modularity.igraph.html
net_modularity <- modularity(net)
clustering_coefficient <- transitivity(net, type = 'average')
# What to do with this?
Connected_components <- components(net)
#https://igraph.org/r/doc/betweenness.html
net_betweenness <- mean(betweenness(net))
#https://igraph.org/r/doc/closeness.html
net_closeness <- mean(closeness(net))
#Plotting everything!
# Plotting Degrees
vertex_degrees %>%
ggplot( aes(x=degree, y=Freq)) +
geom_line(group=1, color="black") +
geom_point(shape=21, color="black", fill="#777777", size=5) +
annotate("text",
x = max(as.numeric(vertex_degrees$degree))-max(as.numeric(vertex_degrees$degree))/3,
y = max(vertex_degrees$Freq)-(max(vertex_degrees$Freq)/8),
hjust = 0,
label = paste(paste('Nodes:',format(num_vertex,  big.mark = ',')),
paste('Edges:',format(num_edges,  big.mark = ',')),
paste('Diameter:',net_diameter),
paste('Density:',format(net_density, nsmall = 6)),
paste('Clustering Coeff:',format(clustering_coefficient, nsmall = 4)),
paste('Betweeness:',format(net_betweenness, nsmall = 2)),
paste('Closeness:',format(net_closeness, nsmall = 2)),
sep='\n')) +
ggtitle("Facebook users")
#Plotting everything!
# Plotting Degrees
vertex_degrees %>%
ggplot( aes(x=degree, y=Freq)) +
geom_line(group=1, color="black") +
geom_point(shape=21, color="black", fill="#777777", size=5) +
annotate("text",
x = max(as.numeric(vertex_degrees$degree))-max(as.numeric(vertex_degrees$degree))/3,
y = max(vertex_degrees$Freq)-(max(vertex_degrees$Freq)/8),
hjust = 0,
label = paste(paste('Nodes:',format(num_vertex,  big.mark = ',')),
paste('Edges:',format(num_edges,  big.mark = ',')),
paste('Diameter:',net_diameter),
paste('Density:',format(net_density, nsmall = 6)),
paste('Clustering Coeff:',format(clustering_coefficient, nsmall = 4)),
paste('Betweeness:',format(net_betweenness, nsmall = 2)),
paste('Closeness:',format(net_closeness, nsmall = 2)),
sep='\n')) +
ggtitle("Wikipedia votes users")
#Plotting everything!
# Plotting Degrees
vertex_degrees %>%
ggplot( aes(x=degree, y=Freq)) +
geom_line(group=1, color="black") +
geom_point(shape=21, color="black", fill="#777777", size=5) +
annotate("text",
x = max(as.numeric(vertex_degrees$degree))-max(as.numeric(vertex_degrees$degree))/3,
y = max(vertex_degrees$Freq)-(max(vertex_degrees$Freq)/8),
hjust = 0,
label = paste(paste('Nodes:',format(num_vertex,  big.mark = ',')),
paste('Edges:',format(num_edges,  big.mark = ',')),
paste('Diameter:',net_diameter),
paste('Density:',format(net_density, nsmall = 6)),
paste('Clustering Coeff:',format(clustering_coefficient, nsmall = 4)),
paste('Betweeness:',format(net_betweenness, nsmall = 2)),
paste('Closeness:',format(net_closeness, nsmall = 2)),
sep='\n')) +
ggtitle("Wikipedia votes")
#Save graph
#https://igraph.org/r/doc/write_graph.html
write_graph(net, paste(datsets_location,'wikipedia.txt',sep=''), format='pajek')
clustering_coefficient <- transitivity(net, type = 'global') # More weight on high degree nodes
clustering_coefficient <- mean(transitivity(net, type = 'local'), na.rm=TRUE) # Same weight on all
clustering_coefficient <- transitivity(net, type = 'average')
# base path
datsets_location <- 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Graphs Visualization/datasets/'
# Loading data
deezer_nodes <- read.csv(file=paste(datsets_location,'deezer/deezer_europe_edges.csv',sep = ''), sep = ',')
#Creating the graph object
net <- graph_from_data_frame(d=wikipedia_nodes, directed=FALSE)
#Creating the graph object
net <- graph_from_data_frame(d=deezer_nodes, directed=FALSE)
# Calculationg
num_vertex <- length(V(net))
num_edges <- length(E(net))
#https://igraph.org/r/doc/diameter.html
net_density <- graph.density(net)
#Degree distribution
vertex_degrees <- as.data.frame(table(degree(net))) %>% rename(degree = Var1)
#https://igraph.org/r/doc/diameter.html
net_diameter <- diameter(net)
clustering_coefficient <- transitivity(net, type = 'average')
# What to do with this?
Connected_components <- components(net)
#https://igraph.org/r/doc/betweenness.html
net_betweenness <- mean(betweenness(net))
#https://igraph.org/r/doc/closeness.html
net_closeness <- mean(closeness(net))
#Plotting everything!
# Plotting Degrees
vertex_degrees %>%
ggplot( aes(x=degree, y=Freq)) +
geom_line(group=1, color="black") +
geom_point(shape=21, color="black", fill="#ff0092", size=5) +
annotate("text",
x = max(as.numeric(vertex_degrees$degree))-max(as.numeric(vertex_degrees$degree))/3,
y = max(vertex_degrees$Freq)-(max(vertex_degrees$Freq)/8),
hjust = 0,
label = paste(paste('Nodes:',format(num_vertex,  big.mark = ',')),
paste('Edges:',format(num_edges,  big.mark = ',')),
paste('Diameter:',net_diameter),
paste('Density:',format(net_density, nsmall = 6)),
paste('Clustering Coeff:',format(clustering_coefficient, nsmall = 4)),
paste('Betweeness:',format(net_betweenness, nsmall = 2)),
paste('Closeness:',format(net_closeness, nsmall = 2)),
sep='\n')) +
ggtitle("Deezer Users")
# base path
datsets_location <- 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Graphs Visualization/datasets/'
# Loading data
lastfm_nodes <- read.csv(file=paste(datsets_location,'lastfm/lastfm_asia_edges.csv',sep = ''), sep = ',')
#Creating the graph object
net <- graph_from_data_frame(d=lastfm_nodes, directed=FALSE)
# Calculationg
num_vertex <- length(V(net))
num_edges <- length(E(net))
#https://igraph.org/r/doc/diameter.html
net_density <- graph.density(net)
#Degree distribution
vertex_degrees <- as.data.frame(table(degree(net))) %>% rename(degree = Var1)
#https://igraph.org/r/doc/diameter.html
net_diameter <- diameter(net)
clustering_coefficient <- transitivity(net, type = 'average')
# What to do with this?
Connected_components <- components(net)
#https://igraph.org/r/doc/betweenness.html
net_betweenness <- mean(betweenness(net))
#https://igraph.org/r/doc/closeness.html
net_closeness <- mean(closeness(net))
#Plotting everything!
# Plotting Degrees
vertex_degrees %>%
ggplot( aes(x=degree, y=Freq)) +
geom_line(group=1, color="black") +
geom_point(shape=21, color="black", fill="#d51007", size=5) +
annotate("text",
x = max(as.numeric(vertex_degrees$degree))-max(as.numeric(vertex_degrees$degree))/3,
y = max(vertex_degrees$Freq)-(max(vertex_degrees$Freq)/8),
hjust = 0,
label = paste(paste('Nodes:',format(num_vertex,  big.mark = ',')),
paste('Edges:',format(num_edges,  big.mark = ',')),
paste('Diameter:',net_diameter),
paste('Density:',format(net_density, nsmall = 6)),
paste('Clustering Coeff:',format(clustering_coefficient, nsmall = 4)),
paste('Betweeness:',format(net_betweenness, nsmall = 2)),
paste('Closeness:',format(net_closeness, nsmall = 2)),
sep='\n')) +
ggtitle("LastFM Users")
#Save graph
#https://igraph.org/r/doc/write_graph.html
write_graph(net, paste(datsets_location,'lastfm_users.txt',sep=''), format='pajek')
# base path
datsets_location <- 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Graphs Visualization/datasets/'
# Loading data
deezer_nodes <- read.csv(file=paste(datsets_location,'deezer/deezer_europe_edges.csv',sep = ''), sep = ',')
#Creating the graph object
net <- graph_from_data_frame(d=deezer_nodes, directed=FALSE)
#Save graph
#https://igraph.org/r/doc/write_graph.html
write_graph(net, paste(datsets_location,'deezer_users.txt',sep=''), format='pajek')
# Loading used libraries
library(tidyverse)
library(igraph)
library(GGally)
library(stats)
# base path
datsets_location <- 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Graphs Visualization/datasets/'
# Loading data
twitter_nodes <- read.csv(file=paste(datsets_location,'twitter/twitter_combined.txt',sep = ''), sep = ' ', header=FALSE)
#Creating the graph object
net <- graph_from_data_frame(d=twitter_nodes, directed=FALSE)
# Clean working space
rm(list = ls())
# Loading used libraries
library(tidyverse)
library(igraph)
library(GGally)
library(stats)
# base path
datsets_location <- 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Graphs Visualization/datasets/'
setwd(paste(datsets_location,'pubmed_diabetes/',sep = ''))
dataset_name <- 'PubMed'
dataset_color <- '#00458c'
# Loading data
pubmed_cites <- read.csv(file='data/Pubmed-Diabetes.DIRECTED.cites.tab', sep = '\t', header=FALSE)
pubmed_content <- read.csv(file='data/Pubmed-Diabetes.NODE.paper.tab', sep = '\t', header=FALSE)
pubmed_cites <- pubmed_cites %>%
select(V2,V3) %>%
rename(from=V2,to=V3) %>%
mutate(from=as.integer(sub('paper:','',from)),
to=as.integer(sub('paper:','',to)))
# Numerical values to be given to each class
labels_num <- pubmed_content %>%
select(V2) %>%
rename(label=V2) %>%
unique()
labels_num$numeric <- 1:nrow(labels_num)
pubmed_labels <- pubmed_content %>%
select(V1,V2) %>%
rename(paper=V1,label=V2) %>%
left_join(labels_num, by=c('label'='label'), suffix = c(".x", ".y"))
# Creating the graph object
net <- graph_from_data_frame(d=pubmed_cites, vertices=pubmed_labels, directed=FALSE)
# To avoid multiplex graphs
net <- simplify(net)
# Calculationg
num_vertex <- length(V(net))
num_edges <- length(E(net))
#Save graph
#https://igraph.org/r/doc/write_graph.html
write_graph(net, paste(dataset_name,'_graph.txt',sep=''), format='pajek')
# Clean working space
rm(list = ls())
# base path
datsets_location <- 'D:/Pablo/clases/UJM/2. Semester, 2021/Mining Uncertain Social Networks/Graphs Visualization/datasets/'
setwd(paste(datsets_location,'dancer/third/',sep = ''))
dataset_name <- 'Dancer 03'
dataset_color <- '#2b9469'
# Loading data
graph_data <- file('t1.graph', open='r')
vertices <- data.frame(id=character(),
atributes=character(),
community=character())
edges <- data.frame(from=character(),
to=character())
in_vertices = TRUE;
while (length(one_line <- readLines(graph_data, n = 1, warn = FALSE)) > 0) {
if (one_line == '#')
{
in_vertices = FALSE;
}
if(one_line  != '# Vertices' && one_line  != '# Edges' && one_line  != '#')
{
if(in_vertices)
{
line = as.list(strsplit(one_line, ';')[[1]])
vertices[nrow(vertices) + 1,] = c(line[])
}
else
{
line = as.list(strsplit(one_line, ';')[[1]])
edges[nrow(edges) + 1,] = c(line[])
}
}
}
edges$from <- as.numeric(edges$from)
edges$to <- as.numeric(edges$to)
vertices$id <- as.numeric(vertices$id)
vertices$community <- as.numeric(vertices$community) + 1
vertices <- vertices %>% select(id,community)
# Creating the graph object
net <- graph_from_data_frame(d=edges, vertices=vertices, directed=FALSE)
# To avoid multiplex graphs
net <- simplify(net)
# Calculationg
num_vertex <- length(V(net))
num_edges <- length(E(net))
#https://igraph.org/r/doc/diameter.html
net_density <- graph.density(net)
#Degree distribution
vertex_degrees <- as.data.frame(table(degree(net))) %>% rename(degree = Var1)
#https://igraph.org/r/doc/diameter.html
net_diameter <- diameter(net)
#https://igraph.org/r/doc/modularity.igraph.html
net_modularity <- modularity(net, vertices$community)
#Save graph
#https://igraph.org/r/doc/write_graph.html
write_graph(net, paste(dataset_name,'_graph.txt',sep=''), format='pajek')
#Read graph
#https://igraph.org/r/doc/read_graph.html
net <- read_graph(paste(dataset_name,'_graph.txt',sep=''), format='pajek')
#https://igraph.org/r/doc/transitivity.html
#https://stackoverflow.com/questions/48853610/average-clustering-coefficient-of-a-network-igraph
clustering_coefficient <- transitivity(net, type = 'average')
# What to do with this?
Connected_components <- components(net)
#https://igraph.org/r/doc/betweenness.html
net_betweenness <- mean(betweenness(net))
# Vertex betweenness
vertext_betweennes <- as.data.frame(table(betweenness(net))) %>%
rename(betweenness = Var1)
vertext_betweennes$betweenness <- as.numeric(vertext_betweennes$betweenness)
vertext_betweennes$betweenness <- (vertext_betweennes$betweenness - min(vertext_betweennes$betweenness))/(max(vertext_betweennes$betweenness)-min(vertext_betweennes$betweenness))
#https://igraph.org/r/doc/closeness.html
net_closeness <- mean(closeness(net))
#https://igraph.org/r/doc/components.html
connected_components <- count_components(net)
#Plotting betweenness
# Plotting Degrees
vertext_betweennes %>%
mutate(betweenness=round(betweenness, 1)) %>%
group_by(betweenness) %>%
summarise(Freq=sum(Freq)) %>%
ggplot( aes(x=betweenness, y=Freq)) +
geom_line(group=1, color="black") +
geom_point(shape=21, color="black", fill="#1DA1F2", size=5) +
ggtitle(paste(dataset_name,"Betweenness"))
#Plotting everything!
# Plotting Degrees
vertex_degrees %>%
ggplot( aes(x=degree, y=Freq)) +
geom_line(group=1, color="black") +
geom_point(shape=21, color="black", fill="#1DA1F2", size=5) +
annotate("text",
x = max(as.numeric(vertex_degrees$degree))-max(as.numeric(vertex_degrees$degree))/3,
y = max(vertex_degrees$Freq)-(max(vertex_degrees$Freq)/6),
hjust = 0,
label = paste(paste('Nodes:',format(num_vertex,  big.mark = ',')),
paste('Edges:',format(num_edges,  big.mark = ',')),
paste('Diameter:',net_diameter),
paste('Density:',format(net_density, nsmall = 6)),
paste('Modularity:',format(net_modularity, nsmall = 2)),
paste('Clustering Coeff:',format(clustering_coefficient, nsmall = 4)),
paste('Betweeness:',format(net_betweenness, nsmall = 2)),
paste('Closeness:',format(net_closeness, nsmall = 2)),
paste('Connected Components:',connected_components),
sep='\n')) +
ggtitle(paste(dataset_name,"Graph"))
